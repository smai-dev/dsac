{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9617f328-569d-4d6e-b60f-00acc47faaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "import kds\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import sys\n",
    "import ads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c946a22-b2b7-4a17-ba70-763d95c6f23d",
   "metadata": {},
   "source": [
    "# Student dataset\n",
    "\n",
    "The student dataset is focused on the **education domain**, specifically modeling and predicting academic success. The classification task is to determine whether a first-year college student will pass or fail based on their performance in secondary school and personal learning attributes. The dataset contains **1131 entries** and uses a binary class label, **Pass**, with values of either \"Pass\" or \"Fail.\"  \n",
    "\n",
    "The attributes in the dataset are all numeric and represent a mix of academic performance metrics and non-cognitive learning traits. Academic metrics include scores in Mathematics, English, and **CAO Points**, a measure of performance in Ireland's state exams. Non-cognitive traits capture different learning preferences, such as whether a student learns better through listening (**Auditory**), doing (**Kinaesthetic**), or visual aids (**Visual**). Additionally, motivational aspects are reflected through **extrinsic motivation** (driven by external rewards) and **Intrinsic Motivation** (interest in learning). Attributes like **Self-Efficacy** and **Conscientiousness** provide insights into a student's personality and confidence in their abilities, while **Study Time** reflects weekly study habits.  \n",
    "\n",
    "This dataset allows for the exploration of how various academic and personal traits influence **a student's likelihood of passing**, highlighting the complex interplay between cognitive skills, personality traits, and study behaviors in academic success.\n",
    "\n",
    "\n",
    "Unlike the adult dataset, the student dataset contains no categorical data. Additionally, all columns have **1131 non-null values**, indicating there are no missing entries. This is advantageous for analysis as it removes the need for data imputation or addressing missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f79de7d-d66a-4892-a859-6faa41d051f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "student = pd.read_csv('data/student.csv', sep=';')\n",
    "\n",
    "# Verify the first few rows\n",
    "student.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85651fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "student.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa6771a-2ff5-4c65-94d3-c47448d1e15e",
   "metadata": {},
   "source": [
    "## Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69463090-2a6c-4a52-afe6-4a1345893273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values for categorical columns with mode\n",
    "student = student.copy()\n",
    "for col in student.select_dtypes(include=['object']).columns:\n",
    "    student[col] = student[col].fillna(student[col].mode()[0])\n",
    "\n",
    "# Fill missing values for numerical columns with mean or median\n",
    "for col in student.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    student[col] = student[col].fillna(student[col].mean())\n",
    "# Check for missing values after handling\n",
    "print(\"\\nMissing values after handling:\")\n",
    "print(student.isnull().sum())\n",
    "\n",
    "# Display the first 5 rows of the updated dataset\n",
    "print(\"\\nPreview of updated dataset:\")\n",
    "print(student.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986704a8-65fb-4065-b0ed-0e90107e541c",
   "metadata": {},
   "source": [
    "The dataset is ready for preprocessing steps such as encoding categorical variables (if needed), scaling numerical attributes, and splitting into training and testing sets for further modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c629edc2-1b62-4f13-a362-a976263a1e07",
   "metadata": {},
   "source": [
    "## Encode categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa2afe4-d3f8-483f-a25e-87e421beae88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the dataset\n",
    "student = pd.read_csv('data/student.csv', sep=';')\n",
    "\n",
    "# Create a copy of the student dataset to ensure original remains unchanged\n",
    "student_encoded = student.copy()\n",
    "\n",
    "# Label Encoding for the binary 'Pass' column\n",
    "le = LabelEncoder()\n",
    "student_encoded['Pass'] = le.fit_transform(student_encoded['Pass'])  # Pass -> 1, Fail -> 0\n",
    "\n",
    "# Check for other categorical columns\n",
    "categorical_cols = student_encoded.select_dtypes(include=['object']).columns\n",
    "\n",
    "# If there are additional categorical columns, apply one-hot encoding\n",
    "student_encoded = pd.get_dummies(student_encoded, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Preview the dataset after encoding\n",
    "print(\"Encoded dataset preview:\")\n",
    "print(student_encoded.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5720d84-0076-49ca-977f-6e64ef949735",
   "metadata": {},
   "source": [
    "The dataset is now ready for modeling, as all categorical variables have been encoded, and missing values (if any) have been handled. The Pass column is now encoded as a numerical target variable (1 for \"Pass\", 0 for \"Fail\"), making the dataset ready for training and testing machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665a03e9-c84a-4955-9647-a702dde0179a",
   "metadata": {},
   "source": [
    "## Scale numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb5fbc4-9303-417b-b3d8-cb1e58d0a497",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Instantiate the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale the feature columns\n",
    "student_encoded_scaled = scaler.fit_transform(student_encoded.drop(columns=['Pass']))\n",
    "\n",
    "# Convert the scaled features back into a DataFrame\n",
    "student_encoded_scaled = pd.DataFrame(student_encoded_scaled, columns=student_encoded.drop(columns=['Pass']).columns)\n",
    "student_encoded_scaled['Pass'] = student_encoded['Pass']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ceb918-83ba-4c4b-a36a-dcecb8deb13d",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f75808-06aa-486a-b0c3-76e42134e0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = student.drop('Pass', axis=1)\n",
    "y = student['Pass']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.3, \n",
    "    stratify=y, \n",
    "    random_state=43\n",
    ")\n",
    "\n",
    "# Output the lengths to ensure the split is correct\n",
    "print(len(X_train), len(y_train))  # Training set sizes\n",
    "print(len(X_test), len(y_test))    # Testing set sizes\n",
    "\n",
    "# Initialize the Decision Tree classifier\n",
    "dt_clf = DecisionTreeClassifier(random_state=43)\n",
    "\n",
    "# Train the classifier with the training data\n",
    "dt_clf.fit(X_train, y_train)\n",
    "\n",
    "# Use the trained model to predict the classes of the test data\n",
    "predictions = dt_clf.predict(X_test)\n",
    "\n",
    "# Compute and output the accuracy by comparing the actual test labels with the predicted labels\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de588ba-0bd5-4213-b232-a5bf0bb8e6c7",
   "metadata": {},
   "source": [
    "The output indicates that the model has successfully split the data into training and testing sets, with 791 samples for training and 340 for testing. The accuracy of 100% suggests that the Decision Tree classifier perfectly predicted the test labels. While this is an excellent result, it may also indicate overfitting, where the model has memorized the training data rather than generalizing from it. It's important to further assess the modelâ€™s performance using techniques like cross-validation to ensure it performs well on unseen data and isn't overly complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ff3203-d6e6-4b28-8018-e919fee00ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary function\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Get and output the confusion matrix\n",
    "confusion_m = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_m)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b6ea01-f9b5-4429-8824-650216ae6a69",
   "metadata": {},
   "source": [
    "his confusion matrix indicates a relatively high number of True Positives (172), but also a considerable number of False Positives (43) and False Negatives (42), suggesting that while the model is effective, there are some misclassifications that could be addressed through further tuning or different modeling approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7062896b-3921-4c80-84ae-d353d15a8390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Generate the confusion matrix\n",
    "confusion_m = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Display the confusion matrix using the ConfusionMatrixDisplay class\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=confusion_m, display_labels=[\"Fail\", \"Pass\"])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "\n",
    "# Display the plot\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7491c172-b04d-402e-a561-b14e75d52785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# also output other metrics (by class and overall scores)\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23db06e-555b-4368-9b16-0adda089f4cb",
   "metadata": {},
   "source": [
    "\n",
    "The model performs better in predicting the \"Pass\" class with a precision, recall, and F1-score of 0.80, compared to the \"Fail\" class with scores of 0.66. Overall accuracy is 75%, indicating the model correctly classified 75% of the test samples. The macro average of 0.73 and weighted average of 0.75 reflect a balanced performance across both classes, though there's room for improvement, especially for the \"Fail\" class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dde5a8a-e8f4-4c84-af43-e09a648b8563",
   "metadata": {},
   "source": [
    "the model is better at predicting the \"Pass\" class but struggles more with predicting the \"Fail\" class. Improving recall for the \"Fail\" class and increasing overall precision would help enhance performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fd377f-b288-4f22-9852-0002c90bb749",
   "metadata": {},
   "source": [
    "\n",
    "- The model performs well for the \"Pass\" class but has room for improvement in predicting the \"Fail\" class.\n",
    "- The overall accuracy and weighted averages suggest that the model is performing reasonably well, but further tuning or additional techniques may be needed to improve predictions for the \"Fail\" class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a447e6-28de-470c-9c4d-d8237679bbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score, roc_auc_score, classification_report\n",
    "from scipy.stats import loguniform\n",
    "import numpy as np\n",
    "\n",
    "# Split the data\n",
    "X = student.drop('Pass', axis=1)\n",
    "y = student['Pass']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Define the model (SVM with RBF kernel)\n",
    "svm_model = SVC(kernel='rbf', C=1.0, gamma='scale', probability=True)\n",
    "\n",
    "# Train the model\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "predictions = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"F1-Score:\", f1_score(y_test, predictions, pos_label='Pass'))\n",
    "print(\"AUC:\", roc_auc_score(y_test, svm_model.predict_proba(X_test)[:, 1]))\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "# Adjust hyperparameters, RandomizedSearchCV (FAST VERSION)\n",
    "# Reduced n_iter to 10 and simplified distributions for speed\n",
    "param_distributions = {\n",
    "    'C': loguniform(1e-1, 1e1),      # Search C between 0.1 and 10\n",
    "    'kernel': ['linear', 'rbf'],         # Only test these two\n",
    "    'gamma': ['scale', 'auto']           # Only test these two\n",
    "}\n",
    "\n",
    "# n_jobs=-1 uses all cores\n",
    "# n_iter=10 is much faster (tests only 10 random combinations)\n",
    "random_search = RandomizedSearchCV(\n",
    "    SVC(probability=True, random_state=42), \n",
    "    param_distributions=param_distributions, \n",
    "    n_iter=10, \n",
    "    cv=5, \n",
    "    scoring='f1', \n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", random_search.best_params_)\n",
    "print(\"Best F1 Score:\", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01290804-0a41-4580-95f7-0b7b176184a1",
   "metadata": {},
   "source": [
    "SVM and k-NN are suited for the student dataset due to its numerical features like \"Auditory,\" \"Study Time,\" and \"Motivation,\" which influence the binary target, \"Pass.\" SVM handles high-dimensional data and complex relationships, while k-NN leverages proximity in feature space, making them ideal for capturing patterns in student performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8bee75-96b1-4dc7-b5df-9d76381c26f6",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae55e0ba-b6a0-4087-9708-b88254e1b5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Instantiate the SVM classifier\n",
    "svm_clf = SVC(kernel='rbf', random_state=42)\n",
    "\n",
    "# Train the model on the training data\n",
    "svm_clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6489c6-2863-4c35-8e09-095c1010f233",
   "metadata": {},
   "source": [
    "## Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea948a7f-6caf-4bd0-9908-e379d0128f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Define the SVM model\n",
    "svc_model = SVC(random_state=42)\n",
    "\n",
    "# Train the SVM Model\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "predictions = svc_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f321e12d-f96d-4a7e-a165-e4862febea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "print(classification_report(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe17dff-c3d6-4b16-aff9-2425ce86eaf2",
   "metadata": {},
   "source": [
    "The SVM model is heavily biased toward the \"Pass\" class and fails to correctly identify any \"Fail\" instances. This suggests that the model struggles with class imbalance or the decision boundary is not well-suited to separate the two classes effectively. Further tuning (e.g., balancing the dataset, adjusting hyperparameters, or testing a different kernel) is needed to improve performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24e09c5-e3d9-441a-be10-4c363651b49d",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b545a2e-3c9c-433c-a86c-9526084616c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Assuming X_train and y_train have been previously defined.\n",
    "\n",
    "# Set up the grid search with different hyperparameters\n",
    "param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
    "grid_search = GridSearchCV(SVC(random_state=42), param_grid, cv=5)\n",
    "\n",
    "# Fit the grid search model to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found during the grid search\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Print all results for the parameter grid search\n",
    "print(\"All Results:\")\n",
    "print(grid_search.cv_results_)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c84f42-dbee-46f1-8192-36c371a90538",
   "metadata": {},
   "source": [
    "For C=0.1 and kernel='linear', the mean test score is 0.68648993\n",
    "For C=1 and kernel='linear', the mean test score is 0.68901361\n",
    "For C=10 and kernel='linear', the mean test score is 0.68771595\n",
    "For C=0.1 and kernel='rbf', the mean test score is 0.62831781\n",
    "For C=1 and kernel='rbf', the mean test score is 0.63717857\n",
    "For C=10 and kernel='rbf', the mean test score is 0.62831781\n",
    "The best-performing model according to GridSearchCV is the SVM with a linear kernel and a regularization parameter of C=1. This combination produced the highest mean test score during the cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc48adb-022f-4e01-aede-c1b74c9dce45",
   "metadata": {},
   "source": [
    "## kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd0c0cd-5d5f-4182-9f83-d834ee94623c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Instantiate the k-NN classifier\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Train the model on the training data\n",
    "knn_clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d170e7-e132-4a8d-ae82-22e1ed241952",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386af287-44fc-4065-b7b4-a44ad5cfba6d",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39768fca-8f77-4d3d-a7ed-3ac17e643230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions using 5-fold cross-validation\n",
    "predictions = cross_val_predict(dt_clf, X, y, cv=5)\n",
    "\n",
    "# Output classification report\n",
    "print(classification_report(y, predictions))\n",
    "\n",
    "# Generate and plot the confusion matrix\n",
    "confusion_m = confusion_matrix(y, predictions)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=confusion_m, display_labels=[\"Fail\", \"Pass\"])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "\n",
    "# Display the plot\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d543dd-b9ad-400f-8d2c-930b9ede11cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "confusion_m = confusion_matrix(y, predictions)\n",
    "\n",
    "# Get predictions using 10-fold cross-validation\n",
    "predictions = cross_val_predict(dt_clf, X, y, cv=10)\n",
    "\n",
    "print(classification_report(y, predictions))\n",
    "\n",
    "# Generate and plot the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=confusion_m, display_labels=[\"Fail\", \"Pass\"])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "\n",
    "# Display the plot\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2c65fc-2542-4beb-8946-3c270285a8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, RocCurveDisplay\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ==========================================\n",
    "# 1. Preprocessing (Required for ROC)\n",
    "# ==========================================\n",
    "\n",
    "# Encode target variable to numeric (Pass=1, Fail=0)\n",
    "# RocCurveDisplay requires numeric labels, not strings.\n",
    "le = LabelEncoder()\n",
    "student['Pass'] = le.fit_transform(student['Pass'])\n",
    "\n",
    "# Step 1: Prepare the data\n",
    "X = student.drop('Pass', axis=1)  # Features (all columns except 'Pass')\n",
    "y = student['Pass']  # Target variable\n",
    "\n",
    "# Step 2: Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Scale the data\n",
    "# Standardizing features is critical for SVM and beneficial for k-NN.\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ==========================================\n",
    "# 2. Cross-Validation (Your Code)\n",
    "# ==========================================\n",
    "\n",
    "# Step 3: Define the models\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)  # Default k-NN model\n",
    "svm_model = SVC(kernel='linear', C=1, probability=True, random_state=42)  # Optimized SVM based on your previous analysis\n",
    "\n",
    "# Step 4: Evaluate models using cross-validation\n",
    "knn_scores = cross_val_score(knn_model, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "svm_scores = cross_val_score(svm_model, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Step 5: Compare the models\n",
    "print(\"KNN Cross-Validation Accuracy Scores:\", knn_scores)\n",
    "print(\"Mean Accuracy for KNN:\", knn_scores.mean())\n",
    "print(\"SVM Cross-Validation Accuracy Scores:\", svm_scores)\n",
    "print(\"Mean Accuracy for SVM:\", svm_scores.mean())\n",
    "\n",
    "# Step 6: Use cross-validation predictions to evaluate in more detail\n",
    "knn_predictions = cross_val_predict(knn_model, X_train_scaled, y_train, cv=5)\n",
    "svm_predictions = cross_val_predict(svm_model, X_train_scaled, y_train, cv=5)\n",
    "\n",
    "# Print classification reports\n",
    "print(\"\\nKNN Classification Report:\")\n",
    "print(classification_report(y_train, knn_predictions))\n",
    "\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_train, svm_predictions))\n",
    "\n",
    "# Optionally, compare confusion matrices\n",
    "print(\"KNN Confusion Matrix:\")\n",
    "print(confusion_matrix(y_train, knn_predictions))\n",
    "\n",
    "print(\"SVM Confusion Matrix:\")\n",
    "print(confusion_matrix(y_train, svm_predictions))\n",
    "\n",
    "# ==========================================\n",
    "# 3. Redefined ROC Curve\n",
    "# ==========================================\n",
    "\n",
    "# Fit the models on the full training set to generate the ROC\n",
    "# Note: We use the optimized parameters (kernel='linear', C=1) found previously for SVM\n",
    "svm_final = SVC(kernel='linear', C=1, probability=True, random_state=42)\n",
    "svm_final.fit(X_train_scaled, y_train)\n",
    "\n",
    "knn_final = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_final.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Generate ROC Curve for SVM\n",
    "svm_disp = RocCurveDisplay.from_estimator(\n",
    "    svm_final, \n",
    "    X_train_scaled, \n",
    "    y_train\n",
    ")\n",
    "\n",
    "# Generate ROC Curve for k-NN on the same axis\n",
    "knn_disp = RocCurveDisplay.from_estimator(\n",
    "    knn_final, \n",
    "    X_train_scaled, \n",
    "    y_train,\n",
    "    ax=svm_disp.ax_\n",
    ")\n",
    "\n",
    "knn_disp.figure_.suptitle(\"ROC Curve Comparison: Optimized SVM vs k-NN\")\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bee6b2-2dd1-4c07-9c0e-0af5e21d90aa",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed102eb-1d0d-406e-8b62-c7fa44a6227f",
   "metadata": {},
   "source": [
    "\n",
    "KNN performs better overall compared to SVM. Although both models have similar accuracies, KNN is better at handling both classes, especially \"Fail.\" It has more balanced precision and recall.\n",
    "SVM, on the other hand, struggles with predicting \"Fail\" and is biased toward predicting \"Pass,\" leading to a high recall for \"Pass\" but zero precision and recall for \"Fail.\" This can be problematic when both classes are important.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
